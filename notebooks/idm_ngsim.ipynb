{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NGSIM\n",
    "using AutomotiveDrivingModels\n",
    "using AutoViz\n",
    "using Interact # Make video in notebook\n",
    "using Reel # Save video as gif\n",
    "using CSV # For writing to csv\n",
    "using DataFrames # For writing to csv\n",
    "using PyPlot # For in notebook plotting\n",
    "using Distributions\n",
    "using Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video making using recorded cars on ngsim\n",
    "- Trajdatas is what the car trajectories are stored in\n",
    "- We want to color the ego vehicle differently to be able to see it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cairo.CairoSurfaceBase{UInt32}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td1 = load_trajdata(1)\n",
    "\n",
    "scene = Scene(500)\n",
    "temp_scene = get!(scene,td1,1000)\n",
    "dummy = render(temp_scene,ROADWAY_101);\n",
    "typeof(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ngsim_segment_zoomed.mp4\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up for video saving using Reel\n",
    "frames = Frames(MIME(\"image/png\"), fps=10)\n",
    "for i in 400:500\n",
    "    temp_scene = get!(scene,td1,i)\n",
    "    carcolors = Dict{Int,Colorant}()\n",
    "    for veh in temp_scene\n",
    "        #@show veh.id\n",
    "        #carcolors[veh.id] = in(veh.id, egoid) ? colorant\"blue\" : colorant\"green\"\n",
    "        \n",
    "            # Color cars green when they are in segment 3\n",
    "        if veh.state.posF.roadind.tag.segment == 3\n",
    "            carcolors[veh.id] = colorant\"green\"\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    overlays = [TextOverlay(text=[\"$(veh.id)\"], incameraframe=true, \n",
    "                pos=VecSE2(veh.state.posG.x+0.5,veh.state.posG.y+0.5)) for veh in scene]\n",
    "    scene_visual = render(temp_scene, ROADWAY_101, \n",
    "        #cam=CarFollowCamera{Int}(2,5.0),\n",
    "        cam=StaticCamera(VecE2(1966400, 570900), 5.0),\n",
    "        #cam=FitToContentCamera(0.),\n",
    "        overlays,\n",
    "        car_colors=carcolors)\n",
    "    push!(frames,scene_visual)\n",
    "end\n",
    "write(\"ngsim_segment_zoomed.mp4\",frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument 1 loads i101 7:50 to 8:05.\n",
    "# load_trajdata function defined in NGSIM.jl/src/trajdata.jl\n",
    "td1 = load_trajdata(1); \n",
    "\n",
    "scene = Scene(500)\n",
    "egoid = [25,5,8,9,10,12,21] # These vehicle ids will be colored blue if the egoid test is performed\n",
    "\n",
    "# List of the vehicle ids in the scene\n",
    "# veh.id = 2 5 8 9 10 12 13 14 18 20 21 22 23 25 26 27 31 32 34 35 39 48\n",
    "\n",
    "# Drive here in the notebook. Replay the trajectory as recorded in the ngsim data\n",
    "@manipulate for i in 400:500\n",
    "    temp_scene = get!(scene,td1,i)\n",
    "    \n",
    "    carcolors = Dict{Int,Colorant}()\n",
    "    for veh in temp_scene\n",
    "        #@show veh.id\n",
    "        #carcolors[veh.id] = in(veh.id, egoid) ? colorant\"blue\" : colorant\"green\"\n",
    "        \n",
    "            # Color cars green when they are in segment 3\n",
    "        if veh.state.posF.roadind.tag.segment == 3\n",
    "            carcolors[veh.id] = colorant\"green\"\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    overlays = [TextOverlay(text=[\"$(veh.id)\"], incameraframe=true, \n",
    "                pos=VecSE2(veh.state.posG.x+0.5,veh.state.posG.y+0.5)) for veh in scene]\n",
    "    render(temp_scene, ROADWAY_101, \n",
    "        #cam=CarFollowCamera{Int}(2,5.0),\n",
    "        #cam=StaticCamera(VecE2(1966400, 570900), 5.0),\n",
    "         cam=FitToContentCamera(0.),\n",
    "        overlays,\n",
    "        car_colors=carcolors)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 150:160\n",
    "    scene = Scene(500) # Have to create a new scene container every time, wonder how manipulate got by without\n",
    "    t = get!(scene,td1,i)\n",
    "    for veh in t\n",
    "        if veh.state.posF.roadind.tag.segment == 3\n",
    "            print(\"$(veh.id) is in segment 3\\n\")\n",
    "        else\n",
    "            print(\"$(veh.id) not in segment 3\\n\")\n",
    "        #display(t.entities[1].state.posF.roadind.tag.segment)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallucination from prerecorded scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a scene from prerecorded trajdata and try a hallucination from that\n",
    "scene_input = Scene(500)\n",
    "get!(scene_input,td1,300)\n",
    "scene = deepcopy(scene_input)\n",
    "overlays = [TextOverlay(text=[\"$(veh.id)\"], incameraframe=true, \n",
    "                pos=VecSE2(veh.state.posG.x+0.5,veh.state.posG.y+0.5)) for veh in scene];\n",
    "#render(start_scene, ROADWAY_101, cam=StaticCamera(VecE2(1966400, 570900), 5.0),overlays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.entities[2].state.posF.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cars = scene.n\n",
    "models = Dict{Int,DriverModel}()\n",
    "for veh in scene\n",
    "    models[veh.id] = IntelligentDriverModel(v_des=10.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1\n",
    "dt = 0.1\n",
    "rec = SceneRecord(n_steps,dt)\n",
    "simulate!(rec,scene,roadway,models,n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.entities[2].state.posF.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.frames[1].entities[2].state.posF.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the frame after doing the simulation for 1 step\n",
    "carcolors = Dict{Int,Colorant}()\n",
    "carcolors[2] = colorant\"green\"\n",
    "render(rec.frames[1],roadway,cam=CarFollowCamera{Int}(2,5.0),car_colors=carcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hallucinate_a_step (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Example\n",
    "td1 = load_trajdata(1);\n",
    "scene = Scene(500)\n",
    "get!(scene,td1,300)\n",
    "display(scene.entities[2].state.posF.s)\n",
    "roadway = ROADWAY_101;\n",
    "particle = Dict(:v_des=>25.0,:σ=>0.5)\n",
    "hallucinate_a_step(roadway,scene,particle,car_id=scene.entities[2].id)\n",
    "\"\"\"\n",
    "function hallucinate_a_step(roadway,scene_input,particle;car_id=-1)\n",
    "    if car_id==-1 @show \"Please give valid car_id\" end\n",
    "    \n",
    "    scene = deepcopy(scene_input)\n",
    "    #scene = scene_input # This was the failure case\n",
    "    n_cars = scene.n \n",
    "\n",
    "    models = Dict{Int, DriverModel}()\n",
    "    \n",
    "    # Create driver models for all the cars in the scene\n",
    "    for veh in scene\n",
    "        if veh.id == car_id\n",
    "            models[veh.id] = IntelligentDriverModel(;particle...)\n",
    "        else\n",
    "            # TODO: RESEARCH QUESTION: What drives the other vehicles in the hallucination\n",
    "            models[veh.id] = IntelligentDriverModel(v_des=10.0)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    n_steps = 1\n",
    "    dt = 0.1\n",
    "    rec = SceneRecord(n_steps, dt)\n",
    "    \n",
    "    simulate!(rec, scene, roadway, models, n_steps)\n",
    "    \n",
    "    X = Array{Float64}(undef,n_steps, 1)\n",
    "\n",
    "    for t in 1:n_steps\n",
    "        f = rec.frames[n_steps - t + 1]\n",
    "        \n",
    "            # Access the vehicle with id as car_id and return its frenet s\n",
    "        X[t,1] = scene.entities[findfirst(car_id,f)].state.posF.s\n",
    "\n",
    "            # The above one liner in for loop fashion\n",
    "#         for veh in f\n",
    "#             if veh.id == car_id\n",
    "#                 s = veh.state.posF\n",
    "#                 X[t, 1] = s.s #position\n",
    "#                 break\n",
    "#             end\n",
    "#         end\n",
    "    end\n",
    "    return X[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247.9166753982852"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.9120744469647664"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td1 = load_trajdata(1);\n",
    "scene = Scene(500)\n",
    "get!(scene,td1,300)\n",
    "display(scene.entities[1].state.posF.s)\n",
    "roadway = ROADWAY_101;\n",
    "particle = Dict(:v_des=>25.0,:σ=>0.5)\n",
    "hallucinate_a_step(roadway,scene,particle,car_id=scene.entities[1].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to_matrix_form (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function to_matrix_form(p_set_dict)\n",
    "    # Get the number of particles\n",
    "    # Extract keys (i.e. params) and corresponding array of values\n",
    "    num_p = -100\n",
    "    num_params = length(keys(p_set_dict))\n",
    "    \n",
    "    params = Array{Symbol}(undef,num_params,1)\n",
    "    vec_val_vec = Array{Array}(undef,num_params,1) #Array containing associated values for each key\n",
    "    for (kk,kv) in enumerate(p_set_dict)\n",
    "        num_p = length(kv[2])\n",
    "        params[kk] = kv[1]\n",
    "        vec_val_vec[kk] = kv[2]\n",
    "    end\n",
    "    \n",
    "    # Create a matrix with different rows being different parameters and diff cols being diff particles\n",
    "    p_mat = hcat(vec_val_vec...)'\n",
    "    \n",
    "    return p_mat, params, vec_val_vec\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_particle_likelihoods (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_particle_likelihoods(roadway,f,trupos,p_set_dict;car_id=-1)\n",
    "    if car_id==-1 @show \"Please give valid car_id\" end\n",
    "    timestep = 0.1 #TODO: Remove hardcoding\n",
    "    p_mat, params, vec_val_vec = to_matrix_form(p_set_dict)\n",
    "    \n",
    "    num_params=size(p_mat)[1]\n",
    "    num_p = size(p_mat)[2]\n",
    "    lkhd_vec = Array{Float64}(undef,num_p)\n",
    "    for i in 1:num_p    \n",
    "        # Create dict version for a single particle\n",
    "        p_dict = Dict()\n",
    "        for j in 1:num_params\n",
    "            p_dict[params[j]]=vec_val_vec[j][i]\n",
    "        end\n",
    "        \n",
    "        std_dev_acc = p_dict[:σ]\n",
    "        \n",
    "        # hack to avoid the std_dev_pos become negative and error Normal distb\n",
    "        if std_dev_acc <= 0 std_dev_acc = 0.1 end\n",
    "        \n",
    "        # TODO: This math needs to be verified from random variable calculations\n",
    "        std_dev_pos = timestep*timestep*std_dev_acc\n",
    "            \n",
    "        hpos = hallucinate_a_step(roadway,f,p_dict,car_id=car_id)\n",
    "        lkhd_vec[i] = pdf(Normal(hpos,std_dev_pos),trupos[1])\n",
    "    end\n",
    "    return lkhd_vec,p_mat,params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([7.81862e-206, 0.000393595, 367.381, 398.014, 398.716], [10.0 15.0 … 25.0 30.0; 0.1 0.1 … 0.1 0.1], Symbol[:v_des; :σ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_array = [10.,15.,20.,25.,30.]\n",
    "num_p = length(v_array)\n",
    "sig_array = [0.1,0.1,0.1,0.1,0.1]\t\n",
    "p_set_dict = Dict(:v_des=>v_array,:σ=>sig_array)\n",
    "td1 = load_trajdata(1);\n",
    "scene = Scene(500)\n",
    "get!(scene,td1,300)\n",
    "roadway = ROADWAY_101;\n",
    "trupos = hallucinate_a_step(roadway,scene,Dict(:v_des=>25.0,:σ=>0.0),car_id=4)\n",
    "lkhd_vec,p_mat,params = compute_particle_likelihoods(roadway,scene,trupos,p_set_dict,car_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t@test length(lkhd_vec) == num_p\n",
    "\t@test length(params) == 2\n",
    "\t@test size(p_mat)[1] == 2\n",
    "\t@test size(p_mat)[2] == 5\n",
    "\t@test any(isnan,lkhd_vec) == false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_p_one_step (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_p_one_step(roadway,f,trupos,p_set_dict;\n",
    "                            car_id=-1,approach=\"pf\",elite_fraction_percent=20)\n",
    "    if car_id==-1 @show \"Provide valid car_id\" end\n",
    "    \n",
    "    lkhd_vec,p_mat,params = compute_particle_likelihoods(roadway,f,trupos,p_set_dict,car_id=car_id)\n",
    "    \n",
    "    num_params = size(p_mat)[1]\n",
    "    num_p = size(p_mat)[2]\n",
    "    \n",
    "    if approach==\"pf\"\n",
    "        p_weight_vec = weights(lkhd_vec./sum(lkhd_vec)) # Convert to weights form to use julia sampling\n",
    "        idx = sample(1:num_p,p_weight_vec,num_p)\n",
    "        new_p_mat = p_mat[:,idx] #Careful that idx is (size,1) and not (size,2)\n",
    "    end\n",
    "    \n",
    "    if approach==\"cem\"\n",
    "        sortedidx = sortperm(lkhd_vec,rev=true)\n",
    "        numtop = convert(Int64,ceil(num_p*elite_fraction_percent/100.0))\n",
    "        best_particles = p_mat[:,sortedidx[1:numtop]] # elite selection\n",
    "#         @show best_particles\n",
    "        p_distribution = fit(MvNormal,best_particles) # fit distb using elites\n",
    "        new_p_mat = rand(p_distribution,num_p) # sample num_p new particles from dist\n",
    "    end\n",
    "    \n",
    "    new_p_set_dict = to_dict_form(params,new_p_mat)\n",
    "    return new_p_set_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HighD experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Cairo.CairoSurfaceBase{UInt32}(Ptr{Nothing} @0x00000000071f7d40, 1000.0, 600.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render(open(io->read(io, MIME\"text/plain\"(), Roadway), \"ngsim_11_lower.txt\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "highd = open(io->read(io, MIME\"text/plain\"(), Trajdata), \n",
    "    \"trajdata_Data11_Road1_nLIOD3_lower.txt\", \"r\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15277"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(highd.frames) # highd is of type listrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"media/highd.mp4\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roadway_highd = open(io->read(io, MIME\"text/plain\"(), Roadway), \n",
    "    \"ngsim_11_lower.txt\", \"r\")\n",
    "frames = Frames(MIME(\"image/png\"), fps=10)\n",
    "for i in 1000:1000\n",
    "    temp_scene = get!(scene,highd,i)\n",
    "    carcolors = Dict{Int,Colorant}()\n",
    "    for veh in temp_scene\n",
    "        #@show veh.id\n",
    "        #carcolors[veh.id] = in(veh.id, egoid) ? colorant\"blue\" : colorant\"green\"\n",
    "        \n",
    "            # Color cars green when they are in segment 3\n",
    "        if veh.state.posF.roadind.tag.segment == 3\n",
    "            carcolors[veh.id] = colorant\"green\"\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    overlays = [TextOverlay(text=[\"$(veh.id)\"], incameraframe=true, \n",
    "                pos=VecSE2(veh.state.posG.x+0.5,veh.state.posG.y+0.5)) for veh in scene]\n",
    "    scene_visual = render(temp_scene, roadway_highd, \n",
    "        #cam=CarFollowCamera{Int}(2,5.0),\n",
    "        #cam=StaticCamera(VecE2(1966400, 570900), 5.0),\n",
    "        cam=FitToContentCamera(0.),\n",
    "        overlays,\n",
    "        car_colors=carcolors)\n",
    "    push!(frames,scene_visual)\n",
    "end\n",
    "write(\"media/highd.mp4\",frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
