{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changelog\n",
    "- 30 Sep 2019\n",
    "    - Creation\n",
    "    - Goal is to do MOBIL experimentation to demonstrate lane changes\n",
    "    - Idea flow\n",
    "        - Look at some videos to select a situation with enough spacing to make lane change\n",
    "        - Select a vehicle id that is on a slow lane\n",
    "        - Make it want to make a lange change by some selection of parameters\n",
    "- 2 Oct\n",
    "    - Defining in notebook copies of `MOBIL` and `Tim2DDriver` for debugging purposed\n",
    "    - Above did not work because methods being redefined not working (or something like that)\n",
    "    - Found that Maxime had a commit on June 18 fixing MOBIL.jl. Did a git pull \n",
    "    on `.julia/packages/dev/AutomotiveDrivingModels`\n",
    "    - Seems to change lane\n",
    "- 3 Oct\n",
    "    - Influence of stochastictity on the `ProportionalLaneTracker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# using packages\n",
    "using NGSIM\n",
    "using AutomotiveDrivingModels\n",
    "using AutoViz\n",
    "using Reel\n",
    "using Distributions\n",
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global things: timestep, roadway, traj\n",
    "timestep_ngsim = 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# overlays: IDOverlay. my_overlay\n",
    "\"\"\"\n",
    "    IDOverlay\n",
    "Display the ID on top of each entity in a scene.\n",
    "# Fields\n",
    "- `color::Colorant`\n",
    "- `font_size::Int64`\n",
    "\"\"\"\n",
    "mutable struct IDOverlay <: SceneOverlay\n",
    "    color::Colorant\n",
    "    font_size::Int\n",
    "end\n",
    "\n",
    "function AutoViz.render!(rendermodel::RenderModel, overlay::IDOverlay, scene::Scene, \n",
    "                            env::E) where E\n",
    "    font_size = overlay.font_size\n",
    "    for veh in scene\n",
    "        add_instruction!(rendermodel, render_text, (\"$(veh.id)\", veh.state.posG.x, \n",
    "                        veh.state.posG.y, font_size, overlay.color), incameraframe=true)\n",
    "    end\n",
    "    return rendermodel\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    my_overlay\n",
    "Overlaying hallucinated trajectory on the ground truth\n",
    "# Fields\n",
    "- `color::Colorant`\n",
    "- `scene::Scene`\n",
    "\"\"\"\n",
    "struct my_overlay <: SceneOverlay\n",
    "    scene::Scene\n",
    "    color # Needs to be of form colorant\"Colorname\"\n",
    "end\n",
    "\n",
    "function AutoViz.render!(rendermodel::RenderModel,overlay::my_overlay, \n",
    "        scene::Scene, roadway::Roadway)\n",
    "    AutoViz.render!(rendermodel,overlay.scene,car_color = overlay.color)\n",
    "    return rendermodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_place_cars"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function: generate roadway and place cars\n",
    "\"\"\"\n",
    "    function init_place_cars(lane_place_array;road_length = 1000.0)\n",
    "- Place cars on a straight roadway of `road_length` according to elems in `lane_place_array`\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "pos_vel_array_1 = [(200.,30.),(215.,0.),(220.,0.)]\n",
    "pos_vel_array_2 = [(200.,0.),(215.,0.),(220.,20.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2,pos_vel_array_3]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "```\n",
    "\"\"\"\n",
    "function init_place_cars(lane_place_array;road_length = 1000.0)\n",
    "    num_lanes = length(lane_place_array)\n",
    "    roadway = gen_straight_roadway(num_lanes,road_length)\n",
    "    scene = Scene()\n",
    "\n",
    "    id = 1\n",
    "    for i in 1:num_lanes\n",
    "        for j in 1:length(lane_place_array[i])\n",
    "            veh_state = VehicleState(Frenet(roadway[LaneTag(1,i)],\n",
    "                    lane_place_array[i][j][1]),roadway,\n",
    "                lane_place_array[i][j][2])\n",
    "            veh = Vehicle(veh_state,VehicleDef(),id)\n",
    "            push!(scene,veh)\n",
    "            id+=1\n",
    "        end\n",
    "    end\n",
    "    return scene,roadway\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multiple_scenelist2video"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function: make video from scene list, make video with overlay from additional scenelist\n",
    "\"\"\"\n",
    "    function scenelist2video\n",
    "- Make video from a list of scenes\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "scenelist2video(scene_list,roadway=roadway)\n",
    "```\n",
    "\"\"\"\n",
    "function scenelist2video(scene_list;roadway,\n",
    "    filename = \"media/mobil/scene_to_video.mp4\")\n",
    "    frames = Frames(MIME(\"image/png\"),fps = 10)\n",
    "    \n",
    "    # Loop over list of scenes and convert to video\n",
    "    for i in 1:length(scene_list)\n",
    "        scene_visual = render(scene_list[i],roadway,\n",
    "        [IDOverlay(colorant\"white\",12)],\n",
    "#         cam=FitToContentCamera(0.),\n",
    "        cam = CarFollowCamera(1)\n",
    "        )\n",
    "        push!(frames,scene_visual)\n",
    "    end\n",
    "    print(\"Making video filename: $(filename)\\n\")\n",
    "    write(filename,frames)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    function scenelist2video\n",
    "- Make video from a list of scenes\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "scenelist2video(scene_list,roadway=roadway)\n",
    "```\n",
    "\"\"\"\n",
    "function multiple_scenelist2video(scene_list_1,scene_list_2;roadway,\n",
    "    filename = \"media/mobil/multiple_scene_to_video.mp4\")\n",
    "    frames = Frames(MIME(\"image/png\"),fps = 10)\n",
    "    @assert length(scene_list_1) == length(scene_list_2)\n",
    "    # Loop over list of scenes and convert to video\n",
    "    for i in 1:length(scene_list)\n",
    "        other_overlay = my_overlay(scene_list_2[i],colorant\"blue\")\n",
    "        scene_visual = render(scene_list[i],roadway,\n",
    "        [IDOverlay(colorant\"white\",12),other_overlay],\n",
    "#         cam=FitToContentCamera(0.),\n",
    "        cam = CarFollowCamera(1)\n",
    "        )\n",
    "        push!(frames,scene_visual)\n",
    "    end\n",
    "    print(\"Making video filename: $(filename)\\n\")\n",
    "    write(filename,frames)\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_hallucination_scenes"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function: hallucinate scene list\n",
    "\"\"\"\n",
    "    function get_hallucination_scenes\n",
    "- Hallucinate starting from `start_step` for `nsteps` using `models` and return a list of scenes\n",
    "- Used by `plot_carwise_pos_vel` to assess position and velocity traces against ground truth\n",
    "\n",
    "# Returns\n",
    "- `halluc_scenes_list`: List containing the scenes starting with the ground truth scene at `start_step`\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "scene_list = get_hallucination_scenes(start_scene,nsteps=100,models=models,\n",
    "roadway=roadway);\n",
    "```\n",
    "\"\"\"\n",
    "function get_hallucination_scenes(start_scene;nsteps,models,start_step=1,\n",
    "        id_list=[],roadway,timestep=0.1,verbosity = false)\n",
    "        # Setting up\n",
    "    scene_halluc = start_scene\n",
    "    halluc_scenes_list = []\n",
    "#     scene_halluc = get_scene(start_step,traj) # Frame to start hallucination from\n",
    "#     push!(halluc_scenes_list,deepcopy(scene_halluc))\n",
    "    \n",
    "    for (i,t) in enumerate(start_step:start_step+nsteps-1)\n",
    "        \n",
    "#         if !isempty(id_list) keep_vehicle_subset!(scene_halluc,id_list) end\n",
    "        \n",
    "        actions = Array{Any}(undef,length(scene_halluc))\n",
    "\n",
    "            # Propagation of scene forward\n",
    "        get_actions!(actions,scene_halluc,roadway,models)\n",
    "\n",
    "        tick!(scene_halluc,roadway,actions,timestep)\n",
    "        \n",
    "        push!(halluc_scenes_list,deepcopy(scene_halluc))\n",
    "    end \n",
    "    return halluc_scenes_list\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making video filename: media/mobil/polite_0.0_lane_change.mp4\n"
     ]
    }
   ],
   "source": [
    "# script: Place cars on a straight roadway and generate driving video\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "\n",
    "models = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "#     print(\"veh.id = $(veh.id)\\n\")\n",
    "#     models[veh.id] = LatLonSeparableDriver(ProportionalLaneTracker(),IntelligentDriverModel())\n",
    "    models[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "politeness = 0.\n",
    "models[1] = Tim2DDriver(timestep_ngsim,mlane=MOBIL(timestep_ngsim,politeness=politeness))\n",
    "models[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list = get_hallucination_scenes(scene,nsteps=100,models=models,roadway=roadway)\n",
    "scenelist2video(scene_list,roadway=roadway,filename=\"media/mobil/polite_$(politeness)_lane_change.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making video filename: media/mobil/compare_politeness.mp4\n"
     ]
    }
   ],
   "source": [
    "# Compare two politeness values in one video by overlaying\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "start_scene = deepcopy(scene)\n",
    "models_1 = Dict{Int64,DriverModel}()\n",
    "models_2 = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "    models_1[veh.id] = IntelligentDriverModel()\n",
    "    models_2[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "politeness = 0.\n",
    "models_1[1] = Tim2DDriver(timestep_ngsim,mlane=MOBIL(timestep_ngsim,politeness=politeness))\n",
    "models_1[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_1 = get_hallucination_scenes(scene,nsteps=100,models=models_1,roadway=roadway)\n",
    "\n",
    "politeness = 1.\n",
    "models_2[1] = Tim2DDriver(timestep_ngsim,mlane=MOBIL(timestep_ngsim,politeness=politeness))\n",
    "models_2[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_2 = get_hallucination_scenes(start_scene,nsteps=100,models=models_2,roadway=roadway)\n",
    "multiple_scenelist2video(scene_list_1,scene_list_2,roadway=roadway,\n",
    "    filename=\"media/mobil/compare_politeness.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making video filename: media/mobil/compare_adv_blueHighThreshold_p_0.mp4\n"
     ]
    }
   ],
   "source": [
    "# Compare two advantage_threshold values in one video by overlaying\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "start_scene = deepcopy(scene)\n",
    "models_1 = Dict{Int64,DriverModel}()\n",
    "models_2 = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "    models_1[veh.id] = IntelligentDriverModel()\n",
    "    models_2[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "politeness = 0.\n",
    "a_th = 0.\n",
    "models_1[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim,politeness=politeness,advantage_threshold=a_th))\n",
    "models_1[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_1 = get_hallucination_scenes(scene,nsteps=100,models=models_1,roadway=roadway)\n",
    "\n",
    "politeness = 0.\n",
    "a_th = 1.\n",
    "models_2[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim,politeness=politeness,advantage_threshold=a_th))\n",
    "models_2[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_2 = get_hallucination_scenes(start_scene,nsteps=100,models=models_2,roadway=roadway)\n",
    "multiple_scenelist2video(scene_list_1,scene_list_2,roadway=roadway,\n",
    "    filename=\"media/mobil/compare_adv_blueHighThreshold_p_0.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making video filename: media/mobil/lateral_blueIsStochastic_3_seed.mp4\n"
     ]
    }
   ],
   "source": [
    "# Influence of stochasticity on lateral driving\n",
    "seed=3;\n",
    "Random.seed!(seed) # To control the stochasticity in ProportionalLaneTracker\n",
    "\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "start_scene = deepcopy(scene)\n",
    "models_1 = Dict{Int64,DriverModel}()\n",
    "models_2 = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "    models_1[veh.id] = IntelligentDriverModel()\n",
    "    models_2[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "models_1[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim),\n",
    "    mlat=ProportionalLaneTracker()\n",
    ")\n",
    "models_1[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_1 = get_hallucination_scenes(scene,nsteps=100,models=models_1,roadway=roadway)\n",
    "\n",
    "models_2[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim),\n",
    "    mlat=ProportionalLaneTracker(Ïƒ=1.)\n",
    ")\n",
    "models_2[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_2 = get_hallucination_scenes(start_scene,nsteps=100,models=models_2,roadway=roadway)\n",
    "multiple_scenelist2video(scene_list_1,scene_list_2,roadway=roadway,\n",
    "    filename=\"media/mobil/lateral_blueIsStochastic_$(seed)_seed.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
